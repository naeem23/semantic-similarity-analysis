# Semantic Similarity Analysis of Textual Data

This project is designed to analyze the semantic similarity between textual data (words/phrases or documents) using OpenAI's embedding models. It calculates cosine similarity scores for pairs of embeddings generated by three different OpenAI models: 'text-embedding-ada-002', 'text-embedding-3-small', and 'text-embedding-3-large'. The results are saved in a CSV file, and a Python script is provided to visualize the similarity scores using a scatter plot.

# Features
   * Textual Data Comparison: Compare semantic similarity at the Word or Phrase Level or Document Level.

   * Multiple Input Options: Accepts multiple source and reference inputs for comparison.

   * Folder Input Support: Allows users to input directories for document-level comparison.
   
   * Similarity Score: Calculates similarity scores using cosine similarity for three embedding models.

   * CSV Output: Saves similarity scores in a CSV file (`similarity_results.csv`) in the `Output` folder and in `bin\Debug\net9.0` folder with columns: Source, Reference, Score_Ada, Score_Small, Score_Large. Also creates two other CSV files name `source_scalar_values.csv` and `reference_scalar_values.csv` in the same directory to store scalar value of sources and references.

   * Visualization: Provides a Python script (`similarity-score-visualization.py`) to generate a bar chart to visualize the similarity scores of a reference (word/phrase or document) with other sources (word/phrases or documents) in terms of 3 different models. Another python script (`scalar-value-visualization.py`) to visualize scalar values of source vs reference. 


# Prerequisites

Before running the project, ensure you have the following installed:

   * .NET Framework: The project is built using the .NET Framework version 9.0.

   * OpenAI API Key: You need an OpenAI API key to generate embeddings. Add your API key to the configuration file (.env).

   * Python: Required for running the visualization script. This project uses Python 3.10.6.
   
   * NuGet Packages: The project uses the following packages. Install them via ```dotnet add package``` or restore them automatically with ```dotnet restore```:  

     * Core Packages:  
        CsvHelper by Josh Close (for reading writing CSV files)  
        DotNetEnv by DotNetEnv (to load environment variable from .env files)  
        itext7 by Apryse Software (for PDF parsing)  
        Newtonsoft.Json by James Newton-King (for JSON serialization)  
        OpenAI by OpenAI (for OpenAI service API)  
        RestSharp by .NET Foundation and Contributors (Simple REST and HTTP API Client)  
        Xceed.Words.NET by Xceed (for Microsoft Word documents parsing)  

      * Testing Packages (for test projects):  
        Microsoft.NET.Test.Sdk (by Microsoft)  
        MSTest.TestAdapter (by Microsoft)  
        MSTest.TestFramework (by Microsoft)  
        xunit (by jnewkirk,bradwilson)  
        xunit.runner.visualstudio (by jnewkirk,bradwilson)  
        Moq (by Daniel Cazzulino, kzu)  
        coverlet.collector (by tonerdo)  
    
   * Python Dependencies: Install the required Python packages using the python-requirements.txt file.


# Installation

1. Clone the repository:
   ```
   git clone https://github.com/naeem23/semantic-similarity-analysis.git
   cd semantic-similarity-analysis
   ```

2. Set Up Environment Variables:
Copy the .env.example file to .env in both the main project and test project directories.
Replace YOUR_API_KEY_HERE with your actual OpenAI API key in both .env files.
   ```
   OPENAI_API_KEY=your_api_key_here
   ```

4. Install the required .NET packages:
Restore the packages using:
    ```
    dotnet restore
    ```
Alternatively, install packages manually (if needed):  
Core packages:  
```
dotnet add package CsvHelper
dotnet add package DotNetEnv
dotnet add package itext7
dotnet add package Newtonsoft.Json
dotnet add package OpenAI
dotnet add package RestSharp
dotnet add package Xceed.Words.NET
```  

Testing packages:  
```
dotnet add package Microsoft.NET.Test.Sdk
dotnet add package MSTest.TestAdapter
dotnet add package MSTest.TestFramework
dotnet add package xunit
dotnet add package xunit.runner.visualstudio
dotnet add package Moq
dotnet add package coverlet.collector
```

6. Install Python dependencies:
   ```
   pip install -r python-requirements.txt
   ```


# Usage

   1. Run the .NET Project:
      *  Navigate to the project directory and run the project:
      ```
      dotnet run
      ```
      
      * The program will prompt you to choose between word/phrase level or document level comparison.

      * For word/phrase level, enter multiple source and reference inputs (one per line).

      * For document level, provide the paths to the source and reference folders.

      * The similarity scores will be calculated and saved in the `similarity_results.csv` file.

      * Scalar values of each source and reference embedding will be saved in `source_scalar_values.csv` and `reference_scalar_values.csv` repectively.

   2. Visualize the Results:
      * Navigate to the Python folder:
        ```
        cd Python
        ```
         
      * Run following python command to visualize similarity score of a reference word/phrase or documents against some source word/phrase or documents:
        ```
        python similarity-score-visualization.py
        ```

      * Run python command to visualize scalar values of source and reference word/phrase or documents:
        ```
        python scalar-value-visualization.py
        ```

      * Each time you run the python script a web server will open in your browser, displaying bar chart for similarity scores and  scatter plot for scalar values.


# Project Folder Structure
  ![image](https://github.com/user-attachments/assets/e9f0f9d7-8fcd-4293-b861-c938889db977)  
  Fig 1: Project folder structure


# Configuration

   * Add your OpenAI API key to the appropriate configuration file (e.g., .env).
     ![image](https://github.com/user-attachments/assets/4d1367cb-26e8-4c1a-bd44-a26d21aa3229)   
    Fig 2: .env file with env variable format

   * Modify the Output folder path in the code if needed. Go to `\SemanticSimilarity\Utilites\OutputGenerator.cs` file and modify following line of code. Create a folder in the root directory `\SemanticSimilarity\` and replace `"Output"` with your folder name.  
     ```
     public async Task GenerateOutputAsync(List<string> sourceContents, List<string> refContents)
     {
         ...
         string projectRoot = Directory.GetParent(AppContext.BaseDirectory).Parent.Parent.Parent.FullName;
         string outputFilePath = Path.Combine(projectRoot, "Output", "similarity_results.csv");
         string srcScalarOutputFilePath = Path.Combine(projectRoot, "Output", "source_scalar_values.csv");
         string refScalarOutputFilePath = Path.Combine(projectRoot, "Output", "reference_scalar_values.csv");
         ... 
     }
     ```


# Example
Input:
* Word/Phrase Level:  
Source: "machine learning", "artificial intelligence"  
Reference: "deep learning", "neural networks"  
![image](https://github.com/user-attachments/assets/37bc3e02-4136-4552-8334-a61a609cb88f)  
Fig 3: Word/pharse level input collection from user using command prompt

* Document Level:  
Source Folder: `G:\FUAS\SE\semantic-similarity-analysis\SemanticSimilarity\Input\Sources`  
Reference Folder: `G:\FUAS\SE\semantic-similarity-analysis\SemanticSimilarity\Input\References`  
![image](https://github.com/user-attachments/assets/4b73bd81-0781-454e-9719-568f94ed9511)  
Fig 4: Document level input collection from user using command prompt


# Output:
Similarity score of different source and reference word/phrase pair produce following output for 3 different embedding model of OpenAI and saves in `similarity_results.csv`. Where ScoreAda refer to similarity score generated using text-embedding-ada-002 model, ScoreSmall refer to text-embedding-3-small, and ScoreLarge refer to text-embedding-3-large.    


Fig 5: Similarity score of source and reference word/phrase pair for 3 different model


# Visualization:
The bar chart will display the similarity scores for each model.  
![image](https://github.com/user-attachments/assets/f655b644-5d26-4e22-8e23-b5f008be6e3f)  
Fig 6: Similarity score analysis of a reference word/phrase/documents with other source word/phrase/documents


The scatter plot will display the scalar value for a source-reference pair.
![image](https://github.com/user-attachments/assets/7dd272ec-78f3-4582-9eca-437a2398dd31)  
Fig 7: Scalar value analysis of a source and reference pair using scatter plot


# Test Project
The test project is included to ensure the correctness of the main project. It uses the same .env file for the OpenAI API key.

   1. Run Tests:
        Navigate to the tests directory and run the tests:
        ```
        dotnet test
        ```


# Contributing
   Contributions are welcome! Please open an issue or submit a pull request for any improvements or bug fixes.
